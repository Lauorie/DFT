# Advanced Fine-Tuning Framework for LLMs with Differentiated Loss

![](loss.png)

## âœ¨ é¡¹ç›®ç‰¹è‰²

*   **ğŸš€ å·®å¼‚åŒ–å¾®è°ƒ (DFT) Loss**: åˆ›æ–°çš„è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼Œå®ƒæ ¹æ®æ¨¡å‹å¯¹æ­£ç¡®Tokençš„é¢„æµ‹ç½®ä¿¡åº¦ï¼ˆ`p_correct`ï¼‰åŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡ã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´ä¸“æ³¨äºå·©å›ºâ€œå·²å­¦å¥½â€çš„çŸ¥è¯†ï¼ŒåŒæ—¶é¿å…è¢«â€œè¿‡éš¾â€çš„æ ·æœ¬å¸¦åï¼Œä»è€Œå®ç°æ›´ç¨³å®šã€é«˜æ•ˆçš„æ”¶æ•›ã€‚
*   **âš¡ é«˜æ€§èƒ½ä¸é«˜æ•ˆç‡**:
    *   **åˆ†å¸ƒå¼è®­ç»ƒ**: æ·±åº¦é›†æˆ **DeepSpeed ZeRO-3**ï¼Œæ”¯æŒåœ¨å¤šGPUä¸Šè¿›è¡Œå¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒï¼Œæå¤§ä¼˜åŒ–äº†æ˜¾å­˜å ç”¨ã€‚
    *   **Flash Attention 2**: å†…ç½®æ”¯æŒ `flash_attention_2`ï¼Œæ˜¾è‘—æå‡é•¿åºåˆ—ï¼ˆå¦‚8K+ï¼‰è®­ç»ƒçš„é€Ÿåº¦å’Œæ•ˆç‡ã€‚
    *   **æ¢¯åº¦æ£€æŸ¥ç‚¹ (Gradient Checkpointing)**: æœ‰æ•ˆå‡å°‘è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ˜¾å­˜æ¶ˆè€—ã€‚
    *   **BF16/FP16 æ··åˆç²¾åº¦**: åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚
*   **ğŸ“¦ å¥å£®çš„æ•°æ®å¤„ç†**:
    *   **ChatML æ ¼å¼**: ä¸“ä¸ºå¤„ç† `ChatML` æ ¼å¼çš„å¯¹è¯æ•°æ®è€Œè®¾è®¡ã€‚
    *   **å¤šæºæ•°æ®èåˆ**: èƒ½å¤Ÿè‡ªåŠ¨åŠ è½½ã€éªŒè¯å’Œåˆå¹¶æ¥è‡ªå¤šä¸ªä¸åŒJSONæ–‡ä»¶çš„è®­ç»ƒæ•°æ®ï¼Œå¹¶å¤„ç†schemaä¸ä¸€è‡´çš„é—®é¢˜ã€‚
    *   **é«˜æ•ˆé¢„å¤„ç†**: æ”¯æŒå¤šè¿›ç¨‹æ•°æ®é¢„å¤„ç†ï¼ŒåŠ å¿«æ•°æ®å‡†å¤‡é€Ÿåº¦ã€‚
*   **ğŸ“ å…¨é¢çš„æ—¥å¿—ä¸ç›‘æ§**:
    *   **åˆ†å¸ƒå¼æ—¥å¿—**: å†…ç½®è‡ªå®šä¹‰çš„åˆ†å¸ƒå¼æ—¥å¿—è®°å½•å™¨ï¼Œç¡®ä¿åœ¨å¤šå¡ç¯å¢ƒä¸­æ—¥å¿—æ¸…æ™°ã€ä¸å†—ä½™ã€‚
    *   **è®­ç»ƒæŒ‡æ ‡ç›‘æ§**: æ·±åº¦é›†æˆ **WandB** æˆ– **SwanLab** ç­‰å®éªŒè·Ÿè¸ªå·¥å…·ï¼Œå®æ—¶ç›‘æ§`loss`ã€`grad_norm`ä»¥åŠè‡ªå®šä¹‰çš„ `avg_p_correct` ç­‰å…³é”®æŒ‡æ ‡ã€‚
*   **ğŸ”§ çµæ´»é…ç½®**: æ‰€æœ‰è®­ç»ƒå‚æ•°ï¼ˆæ¨¡å‹ã€æ•°æ®ã€DFTå‚æ•°ã€è®­ç»ƒå‚æ•°ç­‰ï¼‰å‡é€šè¿‡å‘½ä»¤è¡Œè¿›è¡Œé…ç½®ï¼Œæ¸…æ™°æ˜“ç”¨ã€‚

## ğŸ§  DFT Loss å·¥ä½œåŸç†

## **1. SFT çš„æ ‡å‡†å…¬å¼ä¸æ¢¯åº¦**

### **1.1 SFTæŸå¤±å‡½æ•°**

æ ‡å‡†çš„ SFT æŸå¤±ä¸º token-level äº¤å‰ç†µæŸå¤±ï¼ˆä»¥ä¸€ä¸ªâ€œä¸“å®¶æ•°æ®å¯¹â€åˆ†å¸ƒ D ä¸ºæœŸæœ›ï¼‰ï¼š

![SFT Loss](https://latex.codecogs.com/svg.image?L_{\mathrm{SFT}}(\theta)&space;=&space;\mathbb{E}_{(x,&space;y^*)&space;\sim&space;\mathcal{D}}&space;\left[&space;-\log&space;\pi_\theta(y^*|x)&space;\right])

- $x$ï¼šè¾“å…¥ï¼ˆå¦‚é—®é¢˜ã€æŒ‡ä»¤ï¼‰
- $y^*$ï¼šä¸“å®¶ç­”æ¡ˆï¼ˆground-truth æ ‡ç­¾ï¼‰
- ![](https://latex.codecogs.com/svg.inline?\pi_\theta(y^*|x))ï¼šæ¨¡å‹å‚æ•° ![](https://latex.codecogs.com/svg.inline?\theta) ä¸‹ï¼Œè¾“å‡º ![](https://latex.codecogs.com/svg.inline?y^*) çš„æ¦‚ç‡

### **1.2 SFTçš„æ¢¯åº¦**

å¯¹$\theta$æ±‚æ¢¯åº¦ï¼š

![SFT Gradient](https://latex.codecogs.com/svg.image?\nabla_\theta&space;L_{\mathrm{SFT}}(\theta)&space;=&space;\mathbb{E}_{(x,&space;y^*)&space;\sim&space;\mathcal{D}}&space;\left[-\nabla_\theta\log&space;\pi_\theta(y^*|x)\right])

---

## **2. RL ç­–ç•¥æ¢¯åº¦çš„æ ‡å‡†å½¢å¼**

RLçš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–æœŸæœ›å¥–åŠ±ï¼š

![RL Objective](https://latex.codecogs.com/svg.image?J(\theta)&space;=&space;\mathbb{E}_{x&space;\sim&space;\mathcal{D}_x,\,&space;y&space;\sim&space;\pi_\theta(\cdot|x)}&space;[&space;r(x,&space;y)&space;])

- $r(x, y)$ï¼šå¥–åŠ±å‡½æ•°ï¼Œè¡¡é‡$(x, y)$çš„å¥½å

å…¶**ç­–ç•¥æ¢¯åº¦**ä¸ºï¼š

![Policy Gradient](https://latex.codecogs.com/svg.image?\nabla_\theta&space;J(\theta)&space;=&space;\mathbb{E}_{x&space;\sim&space;\mathcal{D}_x,\,&space;y&space;\sim&space;\pi_\theta(\cdot|x)}&space;[&space;\nabla_\theta&space;\log&space;\pi_\theta(y|x)&space;\cdot&space;r(x,&space;y)&space;])

---

## **3. ç”¨é‡è¦æ€§é‡‡æ ·æŠŠSFTçš„æ¢¯åº¦å†™æˆRLå½¢å¼**

### **3.1 é‡æ–°å†™SFTæ¢¯åº¦**

æˆ‘ä»¬å¸Œæœ›æŠŠ SFT æ¢¯åº¦å†™æˆâ€œé‡‡æ ·äº $\pi_\theta$ å¹¶å¸¦æƒé‡â€çš„å½¢å¼ã€‚

**å…³é”®æŠ€å·§ï¼š** é‡è¦æ€§é‡‡æ ·

![Importance Sampling](https://latex.codecogs.com/svg.image?\mathbb{E}_{y^*&space;\sim&space;p^*}&space;[f(y^*)]&space;=&space;\mathbb{E}_{y&space;\sim&space;\pi_\theta}&space;\left[&space;\frac{p^*(y)}{\pi_\theta(y)}&space;f(y)&space;\right])

åœ¨ SFT ä¸­ï¼Œå¯å†™ä¸ºï¼š

![SFT Gradient Rewritten](https://latex.codecogs.com/svg.image?\nabla_\theta&space;L_{\mathrm{SFT}}(\theta)&space;=&space;\mathbb{E}_{x&space;\sim&space;\mathcal{D}_x,\,&space;y&space;\sim&space;\pi_\theta(\cdot|x)}&space;\left[&space;\frac{1[y&space;=&space;y^*]}{\pi_\theta(y|x)}&space;\cdot&space;(&space;-\nabla_\theta&space;\log&space;\pi_\theta(y|x)&space;)&space;\right])

- $1[y = y^*]$ï¼šæŒ‡ç¤ºå‡½æ•°ï¼Œä»…å½“ç”Ÿæˆç»“æœç­‰äºä¸“å®¶ç­”æ¡ˆæ—¶ä¸º 1

---

### **3.2 é‡æ–°æ•´ç†ä¸ºRLç­–ç•¥æ¢¯åº¦ç»“æ„**

å®šä¹‰ï¼š

- **éšå¼å¥–åŠ±**ï¼š![r(x,y)](https://latex.codecogs.com/svg.inline?r(x,%20y)%20=%20\mathbb{1}[y%20=%20y^*])
- **é‡è¦æ€§æƒé‡**ï¼š![w(y|x)](https://latex.codecogs.com/svg.inline?w(y|x)%20=%20\frac{1}{\pi_\theta(y|x)})

åˆ™ SFT æ¢¯åº¦å˜ä¸ºï¼š

![SFT as RL](https://latex.codecogs.com/svg.image?\nabla_\theta&space;L_{\mathrm{SFT}}(\theta)&space;=&space;-&space;\mathbb{E}_{x&space;\sim&space;\mathcal{D}_x,\,&space;y&space;\sim&space;\pi_\theta(\cdot|x)}&space;\left[&space;w(y|x)&space;\cdot&space;r(x,&space;y)&space;\cdot&space;\nabla_\theta&space;\log&space;\pi_\theta(y|x)&space;\right])

å³ï¼šSFT ç­‰ä»·äºä¸€ç§ç‰¹æ®Šå½¢å¼çš„ RLï¼Œå…¶å¥–åŠ±ç¨€ç–ä¸”å— $1/\pi_\theta$ æ”¾å¤§ã€‚

---

## **4. SFTçš„â€œéšå¼å¥–åŠ±é—®é¢˜â€åˆ†æ**

- å¥–åŠ±ï¼šåªæœ‰ç”Ÿæˆ $y^*$ æ—¶ $r=1$ï¼Œå¦åˆ™ä¸º 0
- æƒé‡ï¼š$\frac{1}{\pi_\theta(y^*|x)}$ï¼Œè‹¥æ¨¡å‹åˆå§‹è®¤ä¸º $y^*$ æ¦‚ç‡å¾ˆä½ï¼Œåˆ™æ¢¯åº¦è¢«å‰§çƒˆæ”¾å¤§

ğŸ‘‰ è¿™ä¼šå¯¼è‡´ï¼š
- æ¢¯åº¦çˆ†ç‚¸
- è®­ç»ƒä¸ç¨³å®š
- æ³›åŒ–èƒ½åŠ›ä¸‹é™

---

## **5. DFTçš„ä¿®æ­£ï¼šæ¶ˆé™¤ $1/\pi_\theta$ çš„å½±å“**

**æ ¸å¿ƒæ€æƒ³ï¼š**  
ä¹˜ä¸Š $\pi_\theta(y^*|x)$ æŠµæ¶ˆ $1/\pi_\theta(y^*|x)$ çš„æ”¾å¤§æ•ˆåº”ï¼Œä½¿ç”¨ `stop-gradient` é¿å…åå‘ä¼ æ’­å¹²æ‰°ã€‚

### **5.1 ä¿®æ­£åçš„æ¢¯åº¦ï¼ˆDFTæ¢¯åº¦ï¼‰**

![DFT Gradient](https://latex.codecogs.com/svg.image?\nabla_\theta&space;L_{\mathrm{DFT}}(\theta)&space;=&space;\mathbb{E}_{(x,&space;y^*)&space;\sim&space;\mathcal{D}}&space;\left[&space;-&space;\text{sg}(&space;\pi_\theta(y^*|x)&space;)&space;\cdot&space;\nabla_\theta&space;\log&space;\pi_\theta(y^*|x)&space;\right])

- $\text{sg}(\cdot)$ï¼šstop-gradient ç®—å­ï¼ˆä¸å‚ä¸åå‘ä¼ æ’­ï¼‰

### **5.2 åæ¨DFTçš„æŸå¤±å‡½æ•°**

å¯¹åº”æŸå¤±å‡½æ•°ä¸ºï¼š

![DFT Loss](https://latex.codecogs.com/svg.image?L_{\mathrm{DFT}}(\theta)&space;=&space;\mathbb{E}_{(x,&space;y^*)&space;\sim&space;\mathcal{D}}&space;\left[&space;-\,&space;\text{sg}(&space;\pi_\theta(y^*|x)&space;)&space;\cdot&space;\log&space;\pi_\theta(y^*|x)&space;\right])

### **5.3 Token-level DFTæŸå¤±**

æ¨å¹¿åˆ° token åºåˆ—ï¼š

![Token-level DFT](https://latex.codecogs.com/svg.image?L_{\mathrm{DFT}}(\theta)&space;=&space;\mathbb{E}_{(x,&space;y^*)&space;\sim&space;\mathcal{D}}&space;\left[&space;-&space;\sum_{t=1}^{|y^*|}&space;\text{sg}(&space;\pi_\theta(y^*_t&space;|&space;y^*_{<t},&space;x)&space;)&space;\cdot&space;\log&space;\pi_\theta(y^*_t&space;|&space;y^*_{<t},&space;x)&space;\right])

- $y^*_t$ï¼šç¬¬ $t$ ä¸ª token
- $y^*_{<t}$ï¼šå‰ $t-1$ ä¸ª tokens

---

## **6. æ¨å¯¼æ€»ç»“æµç¨‹å›é¡¾**

1. **SFT çš„äº¤å‰ç†µæŸå¤±ä¸æ¢¯åº¦**
2. **ç”¨é‡è¦æ€§é‡‡æ ·é‡å†™ SFT æ¢¯åº¦åˆ°ç­–ç•¥åˆ†å¸ƒ $\pi_\theta$ ä¸Š**
3. **å‘ç° SFT ç­‰ä»·äºä¸€ä¸ªå¥–åŠ±ç¨€ç–ã€è¢« $1/\pi_\theta$ æ”¾å¤§çš„ RL è¿‡ç¨‹**
4. **åˆ†æè¯¥æ”¾å¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®š**
5. **æå‡º DFTï¼šå¼•å…¥ $\text{sg}(\pi_\theta)$ æŠµæ¶ˆæ”¾å¤§ï¼Œç¨³å®šè®­ç»ƒ**

---

## **æœ€ç»ˆå…¬å¼æ€»ç»“**

### SFTæŸå¤±ä¸æ¢¯åº¦

![SFT Loss](https://latex.codecogs.com/svg.image?L_{\mathrm{SFT}}(\theta)&space;=&space;\mathbb{E}_{(x,&space;y^*)&space;\sim&space;\mathcal{D}}&space;\left[&space;-\log&space;\pi_\theta(y^*|x)&space;\right])

![SFT Grad](https://latex.codecogs.com/svg.image?\nabla_\theta&space;L_{\mathrm{SFT}}(\theta)&space;=&space;\mathbb{E}_{(x,&space;y^*)&space;\sim&space;\mathcal{D}}&space;\left[-\nabla_\theta\log&space;\pi_\theta(y^*|x)\right])

### RLç­–ç•¥æ¢¯åº¦

![RL PG](https://latex.codecogs.com/svg.image?\nabla_\theta&space;J(\theta)&space;=&space;\mathbb{E}_{x&space;\sim&space;\mathcal{D}_x,\,&space;y&space;\sim&space;\pi_\theta(\cdot|x)}&space;[&space;\nabla_\theta&space;\log&space;\pi_\theta(y|x)&space;\cdot&space;r(x,&space;y)&space;])

### ç”¨é‡è¦æ€§é‡‡æ ·é‡å†™SFTæ¢¯åº¦

![SFT as IS](https://latex.codecogs.com/svg.image?\nabla_\theta&space;L_{\mathrm{SFT}}(\theta)&space;=&space;-&space;\mathbb{E}_{x&space;\sim&space;\mathcal{D}_x,\,&space;y&space;\sim&space;\pi_\theta(\cdot|x)}&space;\left[&space;\frac{1[y&space;=&space;y^*]}{\pi_\theta(y|x)}&space;\nabla_\theta&space;\log&space;\pi_\theta(y|x)&space;\right])

### DFTæŸå¤±ï¼ˆtoken-levelï¼Œè®ºæ–‡å…¬å¼9ï¼‰

![DFT Final](https://latex.codecogs.com/svg.image?L_{\mathrm{DFT}}(\theta)&space;=&space;\mathbb{E}_{(x,&space;y^*)&space;\sim&space;\mathcal{D}}&space;\left[&space;-&space;\sum_{t=1}^{|y^*|}&space;\text{sg}(&space;\pi_\theta(y^*_t&space;|&space;y^*_{<t},&space;x)&space;)&space;\cdot&space;\log&space;\pi_\theta(y^*_t&space;|&space;y^*_{<t},&space;x)&space;\right])

> å…¶ä¸­ $\text{sg}(\cdot)$ è¡¨ç¤º stop-gradientï¼Œæƒé‡ä¸å‚ä¸åå‘ä¼ æ’­ã€‚



DFT Lossçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**è®©æ¨¡å‹æ›´å…³æ³¨å®ƒæœ‰æŠŠæ¡å­¦å¯¹çš„ä¸œè¥¿**ã€‚

ä¼ ç»Ÿçš„äº¤å‰ç†µæŸå¤±å¯¹æ‰€æœ‰Tokenä¸€è§†åŒä»ã€‚è€ŒDFTé€šè¿‡ä¸€ä¸ª`dft_alpha`å‚æ•°æ¥è°ƒæ•´è¿™ä¸€è¡Œä¸ºã€‚å…¶æ ¸å¿ƒé€»è¾‘å¦‚ä¸‹ï¼š

```python
# 1. è®¡ç®—æ¨¡å‹é¢„æµ‹æ­£ç¡®Tokençš„æ¦‚ç‡ p_correct
with torch.no_grad():
    probs = F.softmax(shift_logits_flat, dim=-1)
    p_correct = probs.gather(1, correct_labels.unsqueeze(-1)).squeeze(-1)

# 2. æ ¹æ® p_correct å’Œ dft_alpha è®¡ç®—æŸå¤±æƒé‡
# å½“ p_correct -> 1 (æ¨¡å‹å¾ˆè‡ªä¿¡), dft_weight -> 1
# å½“ p_correct -> 0 (æ¨¡å‹ä¸è‡ªä¿¡), dft_weight -> (1 - dft_alpha)
dft_weight = p_correct * self.dft_alpha + (1 - self.dft_alpha)

# 3. å°†æƒé‡åº”ç”¨åˆ°åŸå§‹æŸå¤±ä¸Š
loss_flat = original_loss_flat * dft_weight

# 4. è®¡ç®—æœ€ç»ˆå¹³å‡æŸå¤±
loss = loss_flat.sum() / num_valid_tokens
```

é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹é¢„æµ‹è¶Šä¸å‡†çš„â€œå›°éš¾â€æ ·æœ¬ï¼Œå…¶æŸå¤±æƒé‡å°±è¶Šä½ï¼Œä»è€Œé¿å…äº†è¿™äº›æ ·æœ¬äº§ç”Ÿè¿‡å¤§çš„æ¢¯åº¦æ¥å¹²æ‰°æ¨¡å‹çš„æ•´ä½“æ”¶æ•›è¿›ç¨‹ã€‚

## âš™ï¸ ç¯å¢ƒå‡†å¤‡

1.  å…‹éš†æœ¬ä»“åº“ï¼š
    ```bash
    git clone https://github.com/your-username/your-repo-name.git
    cd your-repo-name
    ```

2.  å»ºè®®ä½¿ç”¨ `conda` åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒï¼š
    ```bash
    conda create -n dft_trainer python=3.10
    conda activate dft_trainer
    ```

3.  å®‰è£…ä¾èµ–ã€‚è¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒä¸­å·²å®‰è£…ä¸æ‚¨çš„CUDAç‰ˆæœ¬åŒ¹é…çš„PyTorchã€‚
    ```bash
    # requirements.txt
    
    # æ ¸å¿ƒä¾èµ–
    torch --pre "torch>=2.1.0"
    transformers "transformers>=4.40.0"
    datasets "datasets>=2.18.0"
    deepspeed "deepspeed>=0.14.0"
    
    # åŠ é€Ÿä¸æ•ˆç‡
    accelerate "accelerate>=0.29.0"
    flash-attn --pre "flash-attn>=2.5.0" --no-build-isolation
    
    # å·¥å…·
    sentencepiece # for tokenization
    protobuf # for tokenization
    
    # å®éªŒè·Ÿè¸ª (å¯é€‰)
    swanlab
    wandb
    ```
    æ‰§è¡Œå®‰è£…ï¼š
    ```bash
    pip install -r requirements.txt
    ```

## ğŸ“š æ•°æ®å‡†å¤‡

æœ¬é¡¹ç›®ä½¿ç”¨æ ‡å‡†çš„ `JSONL` æ–‡ä»¶æ ¼å¼ï¼Œæ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªJSONå¯¹è±¡ã€‚æ¯ä¸ªJSONå¯¹è±¡å¿…é¡»åŒ…å«ä¸€ä¸ª `messages` å­—æ®µï¼Œå…¶å†…å®¹éµå¾ª **ChatML** æ ¼å¼ã€‚

**æ•°æ®æ ¼å¼ç¤ºä¾‹ (`data.jsonl`)**:
```json
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"}, {"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚"}]}
{"messages": [{"role": "user", "content": "å¸®æˆ‘å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—ã€‚"}, {"role": "assistant", "content": "å½“ç„¶ã€‚æ˜¥é£æ‹‚é¢ç»¿èŠ½æ–°ï¼Œç»†é›¨å¦‚ä¸æ¶¦ç‰©é¢‘ã€‚ç”°é‡èŠ¬èŠ³èœ‚è¶èˆï¼Œæ±Ÿå±±å¦‚ç”»é†‰æ¸¸äººã€‚"}]}
```
**å…³é”®ç‚¹**:
*   `messages` æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«å¤šä¸ªå¯¹è¯è½®æ¬¡ã€‚
*   æ¯ä¸ªå¯¹è¯è½®æ¬¡æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« `role` å’Œ `content`ã€‚
*   ä¸ºäº†è®¡ç®—æŸå¤±ï¼Œ`messages` åˆ—è¡¨ä¸­**å¿…é¡»è‡³å°‘åŒ…å«ä¸€ä¸ª `role` ä¸º `assistant` çš„è½®æ¬¡**ï¼Œå› ä¸ºåªæœ‰ `assistant` çš„å›å¤æ‰ä¼šè¢«è®¡å…¥æŸå¤±è®¡ç®—ã€‚

## ğŸš€ å¦‚ä½•å¼€å§‹è®­ç»ƒ

è®­ç»ƒé€šè¿‡ä¸€ä¸ªå¯åŠ¨è„šæœ¬æ¥ç®¡ç†ï¼Œè¯¥è„šæœ¬é…ç½®äº†æ‰€æœ‰å¿…è¦çš„å‚æ•°ã€‚

### 1. DeepSpeed é…ç½®

é¡¹ç›®éœ€è¦ä¸€ä¸ªDeepSpeedé…ç½®æ–‡ä»¶ã€‚è¿™é‡Œæä¾›ä¸€ä¸ªé€‚ç”¨äº **ZeRO-3** çš„æ¨¡æ¿ `ds_config/zero3.json`ã€‚

```json
{
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "wall_clock_breakdown": false,
    "bf16": {
        "enabled": true
    },
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "none"
        },
        "offload_optimizer": {
            "device": "none"
        },
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_prefetch_bucket_size": 1e7,
        "contiguous_gradients": true,
        "overlap_comm": true
    }
}
```

### 2. ç¼–å†™å¯åŠ¨è„šæœ¬

åˆ›å»ºä¸€ä¸ª `train.sh` è„šæœ¬æ¥å¯åŠ¨è®­ç»ƒä»»åŠ¡ã€‚

```bash
#!/bin/bash

export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export TOKENIZERS_PARALLELISM=false

# è®­ç»ƒæ•°æ®æ–‡ä»¶åˆ—è¡¨
DATA_FILES=(
    "/path/to/your/data_part1.json"
    "/path/to/your/data_part2.json"
    # ... more data files
)

# è¾“å‡ºå’Œæ—¥å¿—ç›®å½•
OUTPUT_DIR="output_model"
LOG_DIR="logs"
mkdir -p ${LOG_DIR}
LOG_FILE="${LOG_DIR}/train_$(date +%F_%H%M%S).log"

deepspeed --num_gpus=8 train_dft_fixed.py \
    --model_name_or_path /path/to/your/base_model \
    --torch_dtype bfloat16 \
    --attn_implementation flash_attention_2 \
    --trust_remote_code True \
    --data_files "${DATA_FILES[@]}" \
    --max_length 8192 \
    --preprocessing_num_workers 8 \
    --validation_split_percentage 2.0 \
    --enable_gradient_checkpointing True \
    --dft_alpha 0.7 \
    --bf16 True \
    --num_train_epochs 1 \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --learning_rate 2e-6 \
    --lr_scheduler_type cosine \
    --weight_decay 0.01 \
    --gradient_accumulation_steps 16 \
    --eval_strategy steps \
    --eval_steps 200 \
    --save_strategy steps \
    --save_steps 200 \
    --save_total_limit 3 \
    --save_only_model True \
    --report_to swanlab \
    --logging_steps 10 \
    --warmup_ratio 0.05 \
    --deepspeed ./ds_config/zero3.json \
    --output_dir ${OUTPUT_DIR} \
    --logging_dir ${LOG_DIR} \
    --remove_unused_columns False \
    --ddp_find_unused_parameters False

echo "Training started in background. Log file: ${LOG_FILE}"
```

### 3. è¿è¡Œè®­ç»ƒ

å°†è„šæœ¬è®¾ç½®ä¸ºå¯æ‰§è¡Œå¹¶è¿è¡Œï¼š

```bash
chmod +x train.sh
nohup ./train.sh > ${LOG_FILE} 2>&1 &
```

æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®æ—¶æŸ¥çœ‹æ—¥å¿—ï¼š
```bash
tail -f ${LOG_FILE}
```

## ğŸ“ˆ ç›‘æ§ä¸ç»“æœ

*   **å‘½ä»¤è¡Œæ—¥å¿—**: è®­ç»ƒè¿›åº¦ã€lossç­‰ä¿¡æ¯ä¼šå®æ—¶è¾“å‡ºåˆ°æ‚¨æŒ‡å®šçš„æ—¥å¿—æ–‡ä»¶ä¸­ã€‚
*   **å®éªŒè·Ÿè¸ªå¹³å°**: å¦‚æœæ‚¨é…ç½®äº† `report_to` ä¸º `swanlab` æˆ– `wandb`ï¼Œæ‚¨å¯ä»¥è®¿é—®å¯¹åº”çš„å¹³å°UIï¼ŒæŸ¥çœ‹æ‰€æœ‰æŒ‡æ ‡çš„å›¾è¡¨åŒ–å±•ç¤ºï¼ŒåŒ…æ‹¬ï¼š
    *   `train/loss`: è®­ç»ƒé›†æŸå¤±ï¼Œåº”ç¨³æ­¥ä¸‹é™ã€‚
    *   `eval/loss`: éªŒè¯é›†æŸå¤±ï¼Œæ˜¯è¡¡é‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„å…³é”®ã€‚
    *   `train/grad_norm`: æ¢¯åº¦èŒƒæ•°ï¼Œç”¨äºåˆ¤æ–­è®­ç»ƒç¨³å®šæ€§ã€‚
    *   `train/train/avg_p_correct`: **DFTæ ¸å¿ƒæŒ‡æ ‡**ï¼Œåæ˜ æ¨¡å‹å¯¹æ­£ç¡®Tokençš„å¹³å‡é¢„æµ‹æ¦‚ç‡ï¼Œåº”ç¨³æ­¥ä¸Šå‡ã€‚
    *   `train/train/dft_alpha`: æ‚¨è®¾ç½®çš„è¶…å‚æ•°ï¼Œç”¨äºéªŒè¯é…ç½®æ˜¯å¦ç”Ÿæ•ˆã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿å¯¹æœ¬é¡¹ç›®è¿›è¡Œè´¡çŒ®ï¼å¦‚æœæ‚¨æœ‰ä»»ä½•æƒ³æ³•ã€å»ºè®®æˆ–å‘ç°äº†bugï¼Œè¯·éšæ—¶æäº¤ Pull Request æˆ–åˆ›å»º Issueã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [Apache 2.0 License](LICENSE) å¼€æºè®¸å¯è¯ã€‚
